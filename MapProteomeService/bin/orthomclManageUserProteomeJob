#!/usr/bin/perl

use lib "$ENV{GUS_HOME}/lib/perl";
use File::Path;
use File::Copy;
use File::stat;
use Sys::Hostname;
use OrthoMCLShared::MapProteomeService::ProteomeJobMgr;
use Digest::MD5 qw(md5_hex);
use JSON;
use strict;
use Carp qw(cluck);

use constant DEBUG => 1;

# Let's face it, this program started out as a simple script and has grown too big.
# Ideally it would be rewritten using a standard OO approach

=pod 

probe the state of orthomcl user's proteome analysis jobs

should be called by cron once every few minutes

** local dir structure **
controlDir/
  newJobs/
    92hty2k/
      info.txt
      proteome.fasta
  phase1/
    runningJobs/
      i83j89/
        info.txt
        input/
          controller.prop
          task.prop
        proteome.fasta
    doneJobs/
      43k8sl0/
        blastSimilarity.out
        info.txt
        input/
          controller.prop
          task.prop
        proteome.fasta
    failedJobs/
      a7bbe32/                (copied from runningJobs/)
  phase2/                     (same as phase1)


** cluster dir structure **
orthomclUserProteomeJobs/
  phase1/
    runningJobs/
      i83j89/
        info.txt
        input/
          controller.prop
          task.prop
        master/
          completedSubtasks.log
          failures/
          mainresult/
          running/
        i83j89.log
        processId
        proteome.fasta
    failedJobs/
      i83j89/        (copied from runningJobs/)
      i83j89.log     (copied from runningJobs/)
  phase2/            (same as phase1)


** info.txt file **
email=
fastaFileName=
submitted=
jobName=

=cut

usage() unless scalar(@ARGV) == 2;

$SIG{'INT'} = 'CLEANUP';

my $serverConfigFile = $ARGV[0];
my $clusterConfigFile = $ARGV[1];

my $fakeTaxonAbbrev = 'xxxx';
my $dbSize; # number of proteins in user input.  global because expensive to compute

my $mgr = OrthoMCLShared::MapProteomeService::ProteomeJobMgr->new($serverConfigFile, $clusterConfigFile);

eval {
  my $controlDir = $mgr->getConfig('serverControlDir');
  my $clusterServerDir = $mgr->getConfig('clusterServerDir');
  my $clusterServer = $mgr->getConfig('clusterServer');
  my $clusterUserName = $mgr->getConfig('clusterUserName');

  warn "[DEBUG] using controlDir $controlDir\n" if DEBUG;
  warn "[DEBUG] using clusterServerDir $clusterServerDir\n" if DEBUG;

  preventConcurrentRun($controlDir);

  makeLocalDirs($controlDir);

  my ($doneJobs1, $failedJobs1, $runningJobsCount1) = checkRunningJobs('phase1', $controlDir, $clusterServerDir);
  my ($doneJobs2, $failedJobs2, $runningJobsCount2) = checkRunningJobs('phase2', $controlDir, $clusterServerDir);

  # phase 1 (self-self blast of user proteome)

  handleDoneJobs($doneJobs1, 'phase1', $controlDir, $clusterServerDir);

  handleFailedJobs($failedJobs1, 'phase1', $controlDir, $clusterServerDir);

  my $startedJobs = handleNewJobs("$controlDir/newJobs",
				  "$controlDir/phase1/runningJobs",
				  "$controlDir/phase1/failedJobs",
				  "$clusterServerDir/phase1/runningJobs",
				  'phase1', $runningJobsCount1 + $runningJobsCount2);

  # phase 2 (blast of user proteome against orthomcl proteins)


  handleDoneJobs($doneJobs2, 'phase2', $controlDir, $clusterServerDir);

  handleFailedJobs($failedJobs2, 'phase2', $controlDir, $clusterServerDir);

  handleNewJobs("$controlDir/phase1/doneJobs",
		"$controlDir/phase2/runningJobs",
		"$controlDir/phase2/failedJobs",
		"$clusterServerDir/phase2/runningJobs",
		'phase2', $runningJobsCount1 + $runningJobsCount2 + $startedJobs);

  # deliver results (process blast results, and deliver results to user)
  # for each phase 2 done job, process it, and delete when done
  deliverResults($controlDir);

  removeStaleFiles($controlDir, $clusterServer, $clusterUserName, $clusterServerDir);

  removeConcurrentRunLock($controlDir);
};

$mgr->error("error: '$@'") if $@;

sub preventConcurrentRun {
  my ($controlDir) = @_;
  my $lockfile = "$controlDir/lock4";
    
  if ( -e $lockfile ) {
    # might be already running
    my $runningJob = `cat $lockfile`;
    chomp $runningJob;
    my @runningJobArray = split(/\t/, $runningJob);

    # if lock found, and process is not on this server, or if on this server and still running, abort
    # (the call to kill is a perl trick to test for process existence)
    if ($runningJobArray[0] ne hostname() || kill(0, $runningJobArray[1])) {
	my $msg = "Lock file found for $runningJob, not starting another process.\n" .
      "If this is in error, rm $lockfile and try again.\n";
	$mgr->log($msg);
	exit 1; # not using "die" to avoid stackstrace from confess in ProteomeJobMgr
    }
  }

  # not currently running, write lockfile with PID information
  open(LOCK, ">$lockfile") or die "could not open lockfile $lockfile\n";
  print LOCK hostname() . "\t$$";
}

sub removeConcurrentRunLock {
  my ($controlDir) = @_;
  my $lockfile = "$controlDir/lock4";
  if ( -e $lockfile ) {
    unlink $lockfile;
  }
}

sub removeStaleFiles {
  my ($controlDir, $clusterServer, $clusterUserName, $clusterServerDir) = @_;

  my $purgeWindow = $mgr->getConfig('purgeWindow');
  my $purgeWindowPlus = "+$purgeWindow";
  my @toPurge = ('phase1/failedJobs', 'phase2/failedJobs');
  foreach my $subdir (@toPurge) {

    my $cmd = "ssh -q -2 $clusterUserName\@$clusterServer 'if [ -a $clusterServerDir/$subdir ]; then find $clusterServerDir/$subdir -mtime $purgeWindowPlus -delete; fi'";
    warn "Running cmd: $cmd \n" if DEBUG;
    system($cmd);

    $cmd = "if [ -a $controlDir/$subdir ]; then find $controlDir/$subdir -mtime $purgeWindowPlus -delete; fi";
    warn "Running cmd: $cmd \n" if DEBUG;
    system($cmd);
  }

  my $resultDir = $mgr->getConfig('resultsDir');
  my $cmd = "if [ -a $resultDir ]; then find $resultDir -mtime $purgeWindowPlus -delete; fi";
  warn "Running cmd: $cmd \n" if DEBUG;
  system($cmd);
}


##################################################
# handle running jobs
##################################################

sub checkRunningJobs {
  my ($phase, $controlDir, $clusterServerDir) = @_;

  warn "[DEBUG] checkRunningJobs() for phase $phase\n" if DEBUG;

  my $clusterUserName = $mgr->getConfig('clusterUserName');
  my $rcfile = $mgr->getConfig('rcfile');
  my $clusterServer = $mgr->getConfig('clusterServer');

  my $runningJobsDir = "$controlDir/$phase/runningJobs";
  opendir(DIR, $runningJobsDir) || die "Can't open $phase runningJobs/ directory '$runningJobsDir'\n";
  my @runningJobs = readdir(DIR);
  closedir(DIR);

  my $doneJobs;
  my $failedJobs;
  my $count;
  foreach my $runningJob (@runningJobs) {
    next if $runningJob =~ /^\./;
    my $clusterRunningJobDir = "$clusterServerDir/$phase/runningJobs/$runningJob";
    if (!clusterTaskRunning($clusterRunningJobDir, $clusterUserName, $clusterServer)) {
      $mgr->log("Found $phase job that has finished running: $runningJob");
      my $logFile = "$clusterRunningJobDir/$runningJob.log";
      my $done;
      eval {
	$done = $mgr->runCmd(0, "ssh -q -2 $clusterUserName\@$clusterServer '/bin/bash -rcfile $rcfile -i -c \"if [ -a $logFile ]; then tail -1 $logFile; fi\"'");
      };
      $mgr->log("Warning: Could not check done status of no-longer-running $phase job $runningJob. Forced to fail the job. $@\n") if $@;
      if ($done && $done =~ /Done/) {
        push(@$doneJobs, $runningJob);
      } else {
        push(@$failedJobs, $runningJob);
      }
    } else {
      $count++
    }
  }

  return ($doneJobs, $failedJobs, $count);
}

sub clusterTaskRunning {
  my ($clusterJobDir, $clusterUserName, $clusterServer) = @_;

  warn "[DEBUG] clusterTaskRunning() for user $clusterUserName to server $clusterServer in job directory $clusterJobDir \n" if DEBUG;

  my $processId = `ssh -q -2 $clusterUserName\@$clusterServer 'if [ -a $clusterJobDir/processId ];then cat $clusterJobDir/processId; fi'`;

  chomp $processId;

  my $status = 0;
  if ($processId) {
    system("ssh -q -2 $clusterUserName\@$clusterServer 'ps -p $processId > /dev/null'");
    $status = $? >> 8;
    $status = !$status;
  }
  return $status;
}


##################################################
# handle completed jobs
##################################################
sub handleDoneJobs {
  my ($doneJobs, $phase, $controlDir, $clusterServerDir) = @_;

  warn "[DEBUG] handleDoneJobs() for $doneJobs in phase $phase\n" if DEBUG;

  my $clusterUserName = $mgr->getConfig('clusterUserName');
  my $rcfile = $mgr->getConfig('rcfile');
  my $clusterServer = $mgr->getConfig('clusterServer');
  my $localRunningDir = "$controlDir/$phase/runningJobs";
  my $localDoneDir = "$controlDir/$phase/doneJobs";
  my $localFailedDir = "$controlDir/$phase/failedJobs";

  foreach my $doneJob (@$doneJobs) {

    eval {

      $mgr->log("Handling done $phase cluster job: $doneJob");
      moveFile("$localRunningDir/$doneJob", "$localDoneDir/$doneJob");

      # zip blast result
      $mgr->log("  gzipping blast result on cluster");
      my $clusterRunningJobDir = "$clusterServerDir/$phase/runningJobs/$doneJob";
      $mgr->runCmd(0, "ssh -q -2 $clusterUserName\@$clusterServer '/bin/bash -rcfile $rcfile -i -c \"gzip $clusterRunningJobDir/master/mainresult/blastSimilarity.out\"'");

      # copy result from cluster
      $mgr->log("  copying from cluster");
      $mgr->getCluster()->copyFrom("$clusterRunningJobDir/master/mainresult", 'blastSimilarity.out.gz', "$localDoneDir/$doneJob");

      moveFile("$localDoneDir/$doneJob/blastSimilarity.out.gz", "$localDoneDir/$doneJob/${phase}BlastSimilarity.out.gz");

      # check that phase 2 had non-empty blast results
      if ($phase eq 'phase2' && -s "$localDoneDir/$doneJob/${phase}BlastSimilarity.out.gz" == 0) {
	# oops, bad blast result.   move to failure dirs locally and on cluster, and mail user
	$mgr->log("  empty phase2 blast results for job $doneJob.  Moving to failures dir and sending user mail.");
	$mgr->runCmd(0, "ssh -q -2 $clusterUserName\@$clusterServer '/bin/bash -rcfile $rcfile -i -c \"mv $clusterRunningJobDir $clusterServerDir/$phase/failedJobs\"'");
	moveFile("$localDoneDir/$doneJob", "$localFailedDir/$doneJob");
	mailNoBlastResults("$localFailedDir/$doneJob/info.txt", $doneJob);
      } else {
	# clean up cluster dir
	$mgr->log("  cleaning up cluster job dir");
	$mgr->runCmd(0, "ssh -q -2 $clusterUserName\@$clusterServer '/bin/bash -rcfile $rcfile -i -c \"rm -rf $clusterRunningJobDir\"'");
      }
    };
    if ($@) {
      move("$localRunningDir/$doneJob", "$localFailedDir/$doneJob") if -e "$localRunningDir/$doneJob";
      move("$localDoneDir/$doneJob", "$localFailedDir/$doneJob") if -e "$localDoneDir/$doneJob";
      handleJobError("$localFailedDir/$doneJob/info.txt", $doneJob, "$localFailedDir/$doneJob", "", "Could not handle $phase done job $doneJob. Moved to failedJobs/. $@");
    }
  }
}

sub deliverResults {
  my ($controlDir) = @_;
  my $phase2DoneDir = "$controlDir/phase2/doneJobs";
  opendir(DIR, $phase2DoneDir) || die "Can't open phase2 doneJobs/ directory '$phase2DoneDir'\n";
  my @donePhase2Jobs = readdir(DIR);
  closedir(DIR);

  mkpath("$controlDir/phase2/doneJobsDebug");
  chdir($controlDir); # be sure cwd is not a job dir that will be rm'd

  foreach my $phase2DoneJob (@donePhase2Jobs) {
    next if $phase2DoneJob =~ /^\./;
    eval {
      $mgr->log("Final processing for $phase2DoneJob");
      deliverResult("$controlDir/phase2/doneJobs/$phase2DoneJob", $phase2DoneJob);
      $mgr->log("  cleaning up local phase2 job dir");

      # move to archive for debugging
      rename("$controlDir/phase2/doneJobs/$phase2DoneJob",
	     "$controlDir/phase2/doneJobsDebug/$phase2DoneJob");

      # remove from archive unless debugging
      rmtree("$controlDir/phase2/doneJobsDebug/$phase2DoneJob") unless DEBUG;
    };
    if ($@) {
      move("$controlDir/phase2/doneJobs/$phase2DoneJob", "$controlDir/phase2/failedJobs/$phase2DoneJob") if -e "$controlDir/phase2/doneJobs/$phase2DoneJob";
      handleJobError("$controlDir/phase2/failedJobs/$phase2DoneJob/info.txt", $phase2DoneJob, "$controlDir/phase2/failedJobs/$phase2DoneJob", "", "Could not deliver results for job $phase2DoneJob. Moved to failedJobs/. $@");
    }
  }
}

sub deliverResult {
  my ($donePhase2JobDir, $jobId) = @_;

  my $groupsFile = $mgr->getConfig('groupsFile');
  my $mclBin = $mgr->getConfig('mclBin');
  my $resultDir = $mgr->getConfig('resultsDir');

  # map to groups
  $mgr->log("  mapping to groups");
  mkpath("$donePhase2JobDir/orthomclResult");
  my $cmd = "orthomclMapProteomeToGroups $donePhase2JobDir/phase1BlastSimilarity.out.gz $donePhase2JobDir/phase2BlastSimilarity.out.gz $groupsFile $fakeTaxonAbbrev $donePhase2JobDir/orthomclResult $mclBin $donePhase2JobDir/log";
  $mgr->log("  $cmd");
  $mgr->runCmd(0, $cmd);

  # make README
  my $readmeFile = "$donePhase2JobDir/orthomclResult/README";
  open(R, ">$readmeFile") || die "Can't open readme file '$readmeFile' for writing";
  print R readme();
  close(R);

  # compute elapsed times
  open(S, "$donePhase2JobDir/submitted");
  my $submittedTimeStamp = <S>;
  close(S);
  open(S, "$donePhase2JobDir/phase1_started");
  my $phase1TimeStamp = <S>;
  close(S);
  open(S, "$donePhase2JobDir/phase2_started");
  my $phase2TimeStamp = <S>;
  close(S);

  # save summary info in json
  my $now = time();
  my $total = ($now - $submittedTimeStamp) / 3600;  #hours
  my $wait = ($phase1TimeStamp - $submittedTimeStamp) / 3600;
  my $phase1 = ($phase2TimeStamp - $phase1TimeStamp) / 3600;
  my $phase2 = ($now - $phase2TimeStamp) / 3600;
  my $proteomeSize = stat("$donePhase2JobDir/proteome.fasta")->size;
 # my $summary = (wait => $wait, phase1 => $phase1, phase2 => $phase2, total => $total, submitted => $mgr->formatLocalTime(localtime($submittedTimeStamp)), proteomeSize=> $proteomeSize);
  my $summary = (wait => $wait, phase1 => $phase1, phase2 => $phase2, total => $total, proteomeSize=> $proteomeSize);
  my $summaryJson = json_encode($summary);

  # zip result
  copy("$donePhase2JobDir/info.txt", "$donePhase2JobDir/orthomclResult");
  $mgr->log("  zipping");
  $mgr->runCmd(0, "zip -rj $donePhase2JobDir/orthomclResult $donePhase2JobDir/orthomclResult");

  # move zipped result to delivery dir
  $mgr->log("  moving final result to $resultDir/orthomclResult-$jobId.zip");
  moveFile("$donePhase2JobDir/orthomclResult.zip", "$resultDir/orthomclResult-$jobId.zip");

  # email result
  $mgr->log("  mailing notification");
  mailResult("$donePhase2JobDir/info.txt", $jobId);

  $mgr->log("Job $jobId COMPLETED.\t$summaryJson");

}


##################################################
# handle new jobs
##################################################
sub handleNewJobs {
  my ($newJobsDir, $localRunningDir, $localFailedDir, $clusterRunningDir, $phase, $runningJobsCount) = @_;

  warn "[DEBUG] handleNewJobs() from newJobsDir $newJobsDir, localRunningDir $localRunningDir, clusterRunningDir $clusterRunningDir for phase $phase\n" if DEBUG;

  my $clusterUserName = $mgr->getConfig('clusterUserName');
  my $rcfile = $mgr->getConfig('rcfile');
  my $clusterServer = $mgr->getConfig('clusterServer');
  my $maxJobs = $mgr->getConfig('maxJobs');
  $maxJobs = 100000 unless $maxJobs;

  # find all subdirs 
  opendir(DIR, $newJobsDir) || die "Can't open $phase new jobs directory '$newJobsDir'\n";
  my @newJobs = readdir(DIR);
  closedir(DIR);

  my $countStarted;
  my @sortedNewJobs = sort {-M "$newJobsDir/$b" <=> -M "$newJobsDir/$a" } grep( /^\w/, @newJobs);
  foreach my $newJob (@sortedNewJobs) {

      my $newJobDir = "$newJobsDir/$newJob";

    # tell user the job has been submitted, even if not ready to start yet.
    if (! (-e "$newJobDir/submitted") && $phase eq 'phase1') {
      mailSubmit("$newJobDir/info.txt", $newJob);
      open(S, ">$newJobDir/submitted") || die "Can't open '$newJobDir/submitted' for writing";
      print S time();
      close(S);
    }

    if ($countStarted + $runningJobsCount >= $maxJobs) {
      $mgr->log("Maximum allowed jobs ($maxJobs) already running.  Can't start $newJob $phase until some complete.");
      next;
    }
    $countStarted++;
    $mgr->log("New $phase job: $newJob");

    my $runningJobDir = "$localRunningDir/$newJob";
    my $localInputDir = "$runningJobDir/input";
    my $masterDir = "$runningJobDir/master";
    my $clusterRunningJobDir = "$clusterRunningDir/$newJob";
    my $clusterInputDir = "$clusterRunningJobDir/input";

    eval {
      correctProteomeFile("$newJobDir/orig_proteome.fasta", "$newJobDir/proteome.fasta");

      if ($phase eq 'phase1') {
	my $validateResultError = validateProteomeFile($newJobDir, "proteome.fasta");
	my $maskedSeqError = checkProteomeFileForFullMaskSeqs($newJobDir, "proteome.fasta") if ( ! $validateResultError);
	my $formatResultError = formatProteomeFile($newJobDir, "proteome.fasta") if ( ! $validateResultError && ! $maskedSeqError);

	if (! $validateResultError && ! $maskedSeqError && ! $formatResultError) {
	  mailStarted("$newJobDir/info.txt", $newJob);
	} else {
	  $mgr->log("  invalid fasta");
	  my $reason = $validateResultError . "\n" . $maskedSeqError . "\n" . $formatResultError;
	  mailInvalidFasta("$newJobDir/info.txt", $newJob, $reason);
	  rmtree($newJobDir);
	  next;
	}
      }

      # record time of new phase
      open(S, ">$newJobDir/${phase}_started") || die "Can't open '$newJobDir/${phase}_started' for writing";
      print S time();
      close(S);

      # move new job dir to running/
      mkpath($runningJobDir);
      moveFile($newJobDir, $runningJobDir);

      # move proteome file to localInputDir
      mkpath($localInputDir);
      #$moveFile("$runningJobDir/proteome.fasta", $localInputDir);

      my $dbFilePath =  ($phase eq 'phase1')?
	"$clusterRunningJobDir/proteome.fasta" :
	  $mgr->getConfig('blastDbFilePath');

      # build input/ dir
      makeTaskFile($localInputDir, $clusterInputDir, $clusterRunningJobDir, $dbFilePath);
      makeControllerFile($localInputDir, $clusterInputDir);

      # mirror job to cluster
      $mgr->log("Mirroring $newJob/ to cluster");
      $mgr->getCluster()->copyTo($localRunningDir, $newJob, $clusterRunningDir);

      #     if ($phase eq 'phase1') {
      # 
      #         # formatdb does not return proper exit code.  generate one by
      #         # grepping its log for 'Error'
      #         my $blastBinDir = $mgr->getConfig('blastBinDir');
      #         my $formatdbLog = "$clusterRunningJobDir/formatdb.log";
      #         my $cmd = "$blastBinDir/formatdb -i $dbFilePath -l $formatdbLog -p T;grep ERROR $formatdbLog; if [ \\\$? -eq 0 ]; then false; else true; fi";
      # 
      #         $mgr->log("Formatting proteome.fasta for self-self blast");
      #         $mgr->runCmd(0, "ssh -2 $clusterUserName\@$clusterServer '/bin/bash -rcfile $rcfile -i -c \"$cmd\"'");
      #     }

      # start cluster job
      startJob("$clusterRunningJobDir", $newJob);
    };
    if ($@) {
      move ("$newJobsDir/$newJob", "$localFailedDir/$newJob") if -e "$newJobsDir/$newJob";
      move ("$localRunningDir/$newJob", "$localFailedDir/$newJob") if -e "$localRunningDir/$newJob";
      handleJobError("$localFailedDir/$newJob/info.txt", $newJob, "$localFailedDir/$newJob", "", "Could not handle $phase new job $newJob. Moved to failedJobs/. $@");
    }
  }
  return $countStarted;
}

# blastall fails on fully masked sequences - all X's .
sub checkProteomeFileForFullMaskSeqs {
  my ($newJobDir, $proteomeFilename) = @_;
  my $proteomeFilePath = "$newJobDir/$proteomeFilename";
  my %invalid_seqs;
  my $id;
  my $seq_is_ok = 0;
  die "Fasta file '$proteomeFilePath' does not exist" unless -e $proteomeFilePath;
  system("dos2unix $proteomeFilePath");
  open(P, $proteomeFilePath) || die "Can't open fasta file '$proteomeFilePath'\n";
  while (<P>) {
    chomp;
    next if /^\s*$/;
    if (m/^>/) {
      $seq_is_ok = 0;
      ($id) = $_ =~ m/>$fakeTaxonAbbrev\|(\S+)/;
      delete $invalid_seqs{$id};
      next;
    }
    
    my $l = length($_);
    
    if ( lineIsFullyMasked($_) ) {
      next if $seq_is_ok; # a previous line of sequence was not a full run of X's
      $invalid_seqs{$id}++;
    } else {
      $seq_is_ok = 1;
      delete $invalid_seqs{$id};
      next;
    }
  }
  close(P);
  my $error = "";
  if (keys(%invalid_seqs) > 0) {
    $error  = "The following sequences are 100% masked (all 'X') and are not valid input.\n";
    $error .= join ("\n", keys %invalid_seqs) . "\n";
  }
  return $error;
}

# check for run of X's over full length of line
sub lineIsFullyMasked {
  my ($line) = @_;
  while ($line =~ /(.)/g) {
    return 0 if ($1 !~ m/X/i);
  }
  return 1;
}

# format proteome file with NCBI formatdb and return empty string if successful, error message otherwise
sub formatProteomeFile {
  my ($newJobDir, $proteomeFilename) = @_;
  my $proteomeFilePath = "$newJobDir/$proteomeFilename";
    
  my $formatdbBinDir = $mgr->getConfig('formatdbBinDir');
  my $formatdbLog = "$newJobDir/formatdb.log";

  # (sfischer's original code; exit code seems to be correct in formatdb 2.2.25, so dropping this extra hoop)
  # formatdb does not return proper exit code.  generate one by
  # grepping its log for 'Error'
  # my $cmd = "$formatdbBinDir/formatdb -i $proteomeFilePath -l $formatdbLog -p T;grep ERROR $formatdbLog; if [ \$? -eq 0 ]; then false; else true; fi";

  $mgr->log("Formatting proteome.fasta for self-self blast");
  my $cmd = "$formatdbBinDir/formatdb -i $proteomeFilePath -l $formatdbLog -p T";
  warn "[DEBUG] $cmd" if DEBUG;
  my $status = system($cmd);
  $mgr->log("Failed running: \n$cmd") if ($status);
  my $error = "";
  if ($status) {
    $error = "formatdb failed with\n";
    $error .= `egrep 'WARNING|FATAL' $formatdbLog`;
  }
  return $error;
}

# basic check for fasta file format and sequence # and length limits
sub validateProteomeFile {
  my ($newJobDir, $proteomeFilename) = @_;
  my $proteomeFilePath = "$newJobDir/$proteomeFilename";
  my $length;
  my $seqCount;
  my $error;
  die "Fasta file '$proteomeFilePath' does not exist" unless -e $proteomeFilePath;
  system("dos2unix $proteomeFilePath");
  open(P, $proteomeFilePath) || die "Can't open fasta file '$proteomeFilePath'\n";
  my $foundFirstLine;
  my $badFirstLine;
  while (<P>) {
    next if /^\s*$/;		# skip blank lines
    if (!$foundFirstLine) {
      $badFirstLine = 1 if !/^\>/; # first non-blank line must start with >
      $foundFirstLine = 1;
    }
    $length += length($_);
    $seqCount += 1 if /^\>\S+/;
  }
  close(P);
  if ($badFirstLine || !$seqCount || $seqCount > 100000 || $length > $seqCount * 5000) {
    $error = 
      "The file must be in FASTA format, contain protein sequences, and have not more than 100,000 sequences.
The first line must be blank or be the description line for the first protein.
"
    }
  return $error;
}

sub correctProteomeFile {
  my ($orig_proteomeFile, $proteomeFile) = @_;

  open(O, $orig_proteomeFile) || die "can't open file $orig_proteomeFile\n";
  open(N, ">$proteomeFile") || die "can't open file $proteomeFile for writing\n";
  while (<O>) {
    s/\t/ /g;		    # lose tab chars.  formatdb fails on them.
    s/\>/\>$fakeTaxonAbbrev\|/ if (/\>/);
    print N $_;
  }
  close(O);
  close(N);
}

sub makeTaskFile {
  my ($localInputDir, $clusterInputDir, $clusterRunningJobDir, $dbFilePath) = @_;

  open(F, ">$localInputDir/task.prop") || die "Can't open task prop file '$localInputDir/task.prop' for writing\n";

  my $blastBinDir = $mgr->getConfig('blastBinDir');
  my $clusterUserName = $mgr->getConfig('clusterUserName');
  my $rcfile = $mgr->getConfig('rcfile');
  my $clusterServer = $mgr->getConfig('clusterServer');

  print F
    "blastBinDir=$blastBinDir
dbFilePath=$dbFilePath
inputFilePath=$clusterRunningJobDir/proteome.fasta
dbType=p
regex='(\\S+)'
blastProgram=blastp
blastParamsFile=blastParams
blastVendor=ncbi
printSimSeqsFile=yes
";
  close(F);

  my $orthomclDbSz = findOrthomclDbSize(); # use this size for both phases, to make them consistent.

  # make blastParams file
  my $blastArgs = $mgr->getConfig('blastArgs');
  die "error: do not include -z arg in blastArgs property.  it is discovered dynamically\n" if $blastArgs =~ /z/;
  open(F, ">$localInputDir/blastParams") || die "Can't open blast params file '$localInputDir/blastParams' for writing\n";;
  print F "$blastArgs -z $orthomclDbSz\n";
  close(F);
}

sub findOrthomclDbSize {
  if (!$dbSize) {
    my $clusterUserName = $mgr->getConfig('clusterUserName');
    my $rcfile = $mgr->getConfig('rcfile');
    my $clusterServer = $mgr->getConfig('clusterServer');
    my $dbFilePath = $mgr->getConfig('blastDbFilePath');

    $mgr->log("Counting proteins in $dbFilePath");

    # discover size of blast db (ie, count of orthomcl proteins) from .count file

    my $cmd = "cat $dbFilePath.count";

    my $dbSizeOut = $mgr->runCmd(0, "ssh -q -2 $clusterUserName\@$clusterServer '/bin/bash -rcfile $rcfile -i -c \"$cmd\"'");

    my @a = split(/\s/, $dbSizeOut); # ignore output from login
    $dbSize = $a[$#a];
  }
  return $dbSize;
}

sub makeControllerFile {
  my ($localInputDir, $clusterInputDir) = @_;
  my ($self, $taskInputDir, $slotsPerNode, $taskSize, $taskClass) = @_;

  my $nodePath = $mgr->getConfig('nodePath');
  my $slotsPerNode = $mgr->getConfig('slotsPerNode');
  my $nodeClass = $mgr->getConfig('nodeClass');
  my $taskSize = $mgr->getConfig('taskSize');
  my $taskClass = $mgr->getConfig('taskClass');
  my $nodeClass = $mgr->getConfig('nodeClass');

  my $clusterMasterDir = $clusterInputDir;
  $clusterMasterDir =~ s/input/master/;
  $nodeClass = 'DJob::DistribJob::BprocNode' unless $nodeClass;

  # print out the file
  my $controllerPropFile = "$localInputDir/controller.prop";
  open(F, ">$controllerPropFile")
    || $self->error("Can't open controller prop file '$controllerPropFile' for writing");
  print F 
    "masterdir=$clusterMasterDir
inputdir=$clusterInputDir
nodeWorkingDirsHome=$nodePath
slotspernode=$slotsPerNode
subtasksize=$taskSize
taskclass=$taskClass
nodeclass=$nodeClass
";
  close(F);
}

sub startJob {
  my ($clusterJobDir, $jobId) = @_;

  warn "[DEBUG] startJob() for jobId $jobId in clusterJobDir $clusterJobDir\n" if DEBUG;

  my $clusterUserName = $mgr->getConfig('clusterUserName');
  my $rcfile = $mgr->getConfig('rcfile');
  my $clusterServer = $mgr->getConfig('clusterServer');
  my $numNodes = $mgr->getConfig('numNodes');
  my $clusterQueue = $mgr->getConfig('clusterQueue');
  my $clusterMaxMem = $mgr->getConfig('clusterMaxGigsPerNode');
  my $ppn = $mgr->getConfig('ppn');

  $mgr->log("Starting job on cluster in $clusterJobDir");
  $mgr->runClusterTask($clusterUserName, $rcfile, $clusterServer, "$clusterJobDir/processId", "$clusterJobDir/$jobId.log", "$clusterJobDir/input/controller.prop", $numNodes, 14400, $clusterQueue, $ppn, $clusterMaxMem);
}


##################################################
# handle failed jobs
##################################################
sub handleFailedJobs {
  my ($failedJobs, $phase, $controlDir, $clusterServerDir) = @_;

  warn "[DEBUG] handleFailedJobs() for $failedJobs in phase $phase\n" if DEBUG;

  my $clusterUserName = $mgr->getConfig('clusterUserName');
  my $rcfile = $mgr->getConfig('rcfile');
  my $clusterServer = $mgr->getConfig('clusterServer');
  my $localRunningDir = "$controlDir/$phase/runningJobs";
  my $localFailedDir = "$controlDir/$phase/failedJobs";

  foreach my $failedJob (@$failedJobs) {

    mailServerError("$localRunningDir/$failedJob/info.txt", $failedJob);
    $mgr->log("Handling $phase failed job: $failedJob");
    $mgr->log("  moving local job to $phase failed dir");
    move("$localRunningDir/$failedJob", "$localFailedDir/$failedJob");

    # clean up cluster dir
    $mgr->log("  moving cluster job to $phase cluster failed dir");
    my $clusterRunningJobDir = "$clusterServerDir/$phase/runningJobs/$failedJob";
    my $clusterFailedJobDir = "$clusterServerDir/$phase/failedJobs/$failedJob";

    mailServerErrorToAdmin("$localFailedDir/$failedJob/info.txt", $failedJob, "$localFailedDir/$failedJob", $clusterFailedJobDir, "Job on cluster not running, but log there does not say 'Done'");

    $mgr->runCmd(0, "ssh -q -2 $clusterUserName\@$clusterServer '/bin/bash -rcfile $rcfile -i -c \"if [ -d $clusterRunningJobDir ]; then mv $clusterRunningJobDir $clusterFailedJobDir; fi \"'");
  }
}

sub mailSubmit {
  my ($infoFile, $jobId) = @_;

  my $msg = "
has been submitted.

You will get an email when it starts running (after other jobs ahead in the queue).

You will get a second email when it is done.  At best this will be within a day.  It might be as long as many days, or, sometimes, even weeks, if there is a large backlog.

Feel free to contact us to learn about your job's status.  When you do, be sure to include your job id: $jobId

";
  sendUserMail($infoFile, $jobId, "OrthoMCL Job $jobId - submitted", $msg);
}

sub mailStarted {
  my ($infoFile, $jobId) = @_;

  my $msg = "
has started running.

You will get an email when it is done.  At best this will be within a day.  It might be as long as many days, or, sometimes, even weeks, if there is a large backlog.

Feel free to contact us to learn about your job's status.  When you do, be sure to include your job id: $jobId

";
  sendUserMail($infoFile, $jobId, "OrthoMCL Job $jobId - running", $msg);
}

sub mailServerError {
  my ($infoFile, $jobId) = @_;

  my $msg = "
has failed because of a server error.  Please try again, or respond to this mail to report the problem.
";
  sendUserMail($infoFile, $jobId, "OrthoMCL Job $jobId - server error", $msg);
}

sub mailServerErrorToAdmin {
  my ($infoFile, $jobId, $localFailedJobPath, $remoteFailedJobPath, $errMsg) = @_;
  my $cluster = $mgr->getConfig('clusterServer');
  my $local = `hostname`;
  chomp $local;
  my $msg = "See log and failed job at '$local:$localFailedJobPath' and '$cluster:$remoteFailedJobPath'";
  sendMailToAdmin($infoFile, $jobId, "OrthoMCL Job $jobId - server error", "\n$errMsg\n$msg");
}

sub handleJobError {
  my ($infoFile, $jobId, $localFailedJobPath, $remoteFailedJobPath, $errMsg) = @_;
  $mgr->log("Job Error for $jobId\n$errMsg");
  cluck;
  mailServerError($infoFile, $jobId);
  mailServerErrorToAdmin($infoFile, $jobId, $localFailedJobPath, $remoteFailedJobPath, $errMsg);
}

sub mailInvalidFasta {
  my ($infoFile, $jobId, $reason) = @_;

  my $msg = "
has an invalid sequence file.
$reason
Please resubmit with a valid file.
";
  sendUserMail($infoFile, $jobId, "OrthoMCL Job $jobId - invalid file", $msg);
}

sub mailNoBlastResults {
  my ($infoFile, $jobId) = @_;

  my $msg = "
did not have any blast matches to the OrthoMCL-DB sequences.

The most likely reason is an invalid fasta file.  Please read the instructions on the web form
to be sure you are submitting a valid proteins fasta file.  If you are not sure, send us a
snippet of your fasta file.

If you believe your fasta file is correct, please write back.   It is possible the cause is server error.
";
  sendUserMail($infoFile, $jobId, "OrthoMCL Job $jobId - no matches", $msg);
}

sub mailResult {
  my ($infoFile, $jobId) = @_;

  my $purgeWindow = $mgr->getConfig('purgeWindow');
  my $info = readInfoFile($infoFile);
  my $link = $info->{resultUrl};

  my $msg = "
is complete.  The results are now available at:
  $link

They will be available for $purgeWindow days.
";
  sendUserMail($infoFile, $jobId, "OrthoMCL Job $jobId - done", $msg);
}

sub sendMailToAdmin {
  my ($infoFile, $jobId, $subject, $message) = @_;

  my $adminEmail = $mgr->getConfig('adminEmail');

  my $info;
  eval {
    $info = readInfoFile($infoFile);
    $info->{email} =~ s/^\s+|\s+$//g;  # trim leading and trailing white space
    $info->{email} =~ /^[A-Z0-9._%+-]+@[A-Z0-9.-]+\.[A-Z]{2,4}$/i or die "Illegal email address: '$info->{email}'\n";
  };
  if ($@) {
    $message .= "\nCan't read info file '$infoFile'\n$@\n";
  }

  my @a = split(/\@/, $info->{email});
  my $login = shift(@a);

  my $body = "
Server Error on OrthoMCL job:
  ID:         $jobId
  Name:       $info->{jobName}
  Fasta file: $info->{fastaFileName}
  Submitted:  $info->{submitted} (EST)
$message
";

  open(SENDMAIL, "|/usr/sbin/sendmail -t") or die "Cannot open sendmail: $!\n";
  print SENDMAIL "Subject: $subject\n";
  print SENDMAIL "To: $adminEmail\n";
  print SENDMAIL "From: help\@orthomcl.org\n";
  print SENDMAIL "Content-type: text/plain\n\n";
  print SENDMAIL $body;
  close(SENDMAIL);
}

sub sendUserMail {
  my ($infoFile, $jobId, $subject, $message) = @_;

  eval {
    my $info = readInfoFile($infoFile);
    $info->{email} =~ s/^\s+|\s+$//g;  # trim leading and trailing white space
    $info->{email} =~ /^[A-Z0-9._%+-]+@[A-Z0-9.-]+\.[A-Z]{2,4}$/i or die "Illegal email address: '$info->{email}'\n";

    my @a = split(/\@/, $info->{email});
    my $login = shift(@a);

    my $body = "
Hello $login,

Your OrthoMCL job:
  ID:         $jobId
  Name:       $info->{jobName}
  Fasta file: $info->{fastaFileName}
  Submitted:  $info->{submitted} (EST)
$message
Thank you for using OrthoMCL,
The OrthoMCL Team
";

    open(SENDMAIL, "|/usr/sbin/sendmail -t") || die "Cound not open '|/usr/sbin/sendmail -'";
    print SENDMAIL "Subject: $subject\n";
    print SENDMAIL "To: $info->{email}\n";
    print SENDMAIL "From: help\@orthomcl.org\n";
    print SENDMAIL "Content-type: text/plain\n\n";
    print SENDMAIL $body;
    close(SENDMAIL);
  };
  if ($@) {
    my $msg = "Could not send user email for $jobId.  $@";
    $mgr->log($msg);
    mailServerErrorToAdmin($infoFile, $jobId, "", "", $msg);
  }
}

sub readInfoFile {
  my ($infoFile) = @_;

  open(I, $infoFile) || die "Can't open info file '$infoFile'\n";
  my $info;
  while (<I>) {
    chomp;
    my @array = split(/\=/);
    my $key = shift(@array);
    my $value = join('=', @array);
    $info->{$key} = $value;
  }
  close(I);
  return $info;
}

sub moveFile {
  my ($from, $to) = @_;

 move($from, $to) || die "Could not mv $from $to\n";
}

# include here all dirs that removeStaleFiles with clean up, so the clean up has a place to clean up.
sub makeLocalDirs {
  my ($controlDir) = @_;
  qx(mkdir -p $controlDir/{results,newJobs});
  qx(mkdir -p $controlDir/phase1/{runningJobs,doneJobs,failedJobs});
  qx(mkdir -p $controlDir/phase2/{runningJobs,doneJobs,failedJobs});
  qx(chmod 1777 $controlDir/newJobs);
}

sub CLEANUP {
  my $controlDir = $mgr->getConfig('serverControlDir');
  removeConcurrentRunLock($controlDir);
  exit(1);
}


sub usage {
  print STDERR "

usage:
   orthomclManageUserProteomeJob server_config_file cluster_config_file

** server_config_file **
groupsFile=           (orthomcl groups to map blast results to)
mclBin=               (location of mcl executable)
adminEmail=           (email of admin for err msgs)
uploadIsOffline=      (0/1 indicates if service has been taken offline)
purgeWindow=          (number of days we promise user results will be available for)
formatdbBinDir=       (location of NCBI's formatdb command on webserver)
resultsDir=            (directory in which to put final result, zipped and named after job id)

** cluster_config_file **
serverControlDir=     (local dir to control this job)
maxJobs=              (maximum number of jobs allowed to run at one time, including both phase 1 and phase 2.  Default 100000)
blastDbFilePath=      (blast database file)
clusterUserName=      (login to use to get into cluster server)
rcfile=               (rcfile to prepare bash environment)
clusterServer=        (name of machine)
clusterServerDir=     (dir there to put our stuff in)
clusterQueue=         (queue to use)
numNodes=             (num of nodes to request)
slotsPerNode=         (slots per each node)
ppn=                  (parallelization)
nodePath=             (???)
nodeClass=            (perl class to represent this type of node)
taskSize=             (number of seqs to process in one batch)
taskClass=            (perl class to manage that processing)
blastArgs=            (arguments for blast)
blastBinDir=          (location of blast executable)
";
  exit(1);
}

sub readme {
  return "
Output: A .zip file containing the following text files:

orthomclResults/
  orthologGroups    a map between your proteins and OrthoMCL groups. Tab 
                    delimited.  Columns: your_protein, orthomcl_group, 
                    seq_id_of_best_hit, evalue_mantissa, evalue_exponent,
                    percent_identity, percent_match.
  paralogPairs      reciprocal best hits among those proteins in your genome
                    that were not mapped to OrthoMCL groups, as described
                    below in the Algorithms section.
  paralogGroups     the proteins in paralogPairs clustered into groups by
                    the mcl program, as described below in the Algorithms
                    section.



Algorithm

Please refer to the OrthoMCL Algorithm Document ()for details about how OrthoMCL-DB is created.

    * BLASTP of your proteins against self and against OrthoMCL proteins. Cutoff of e-5, and 50% match.
    * For proteins that have an above-threshold match: assign the group from the best matching OrthoMCL protein. If the best OrthoMCL protein does not have a group, assign NO_GROUP.
    * For remaining proteins: use the InParalog algorithm described in the OrthoMCL Algorithm Document to find potential paralog pairs.
    * Submit those pairs to the MCL program (see the OrthoMCL Algorithm Document). 
";
}
